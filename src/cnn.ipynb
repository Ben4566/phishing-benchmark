{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e0b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laufe auf: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from benchmark import PerformanceMonitor  # Ihr Benchmark-Skript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 1. KONFIGURATION & DATEN ---\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Laufe auf: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2de95b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading legitimate URLs...\n",
      "Loading phishing URLs...\n",
      "Training on 225093 URLs, Testing on 56274 URLs.\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"\n",
    "    Loads URLs and labels from text files into lists.\n",
    "    Returns: (list of strings, list of integers)\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    labels = []\n",
    "\n",
    "    # 1. Load Legitimate URLs (Label = 0)\n",
    "    print(\"Loading legitimate URLs...\")\n",
    "    try:\n",
    "        with open(r\"..\\data\\raw\\url_legitimate_safebrowsing.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                url = parts[0].strip()\n",
    "                if url:\n",
    "                    urls.append(url)\n",
    "                    labels.append(0)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: Legitimate file not found.\")\n",
    "\n",
    "    # 2. Load Phishing URLs (Label = 1)\n",
    "    print(\"Loading phishing URLs...\")\n",
    "    try:\n",
    "        with open(r\"..\\data\\raw\\url_raw_phishing.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                url = parts[0].strip()\n",
    "                if url:\n",
    "                    urls.append(url)\n",
    "                    labels.append(1)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: Phishing file not found.\")\n",
    "\n",
    "    return urls, np.array(labels)\n",
    "\n",
    "# --- 1. PREPARE DATA ---\n",
    "raw_urls, labels = load_raw_data()\n",
    "\n",
    "# Split into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    raw_urls, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training on {len(X_train)} URLs, Testing on {len(X_test)} URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d769603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektorisiere Daten (das dauert kurz)...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. VECTORIZATION (Manuell für PyTorch) ---\n",
    "# Wir bauen ein einfaches Vokabular (Zeichen-basiert), genau wie Keras TextVectorization\n",
    "chars = sorted(list(set(\"\".join(X_train[:1000])))) # Schnelles Vocab aus den ersten 1000 URLs\n",
    "char_to_int = {c: i+2 for i, c in enumerate(chars)} # +2 für Padding (0) und UNK (1)\n",
    "vocab_size = len(char_to_int) + 2\n",
    "\n",
    "def encode_urls(urls, max_len=MAX_LEN):\n",
    "    encoded_batch = []\n",
    "    for url in urls:\n",
    "        # Zeichen zu Int konvertieren\n",
    "        vec = [char_to_int.get(c, 1) for c in url] # 1 = Unknown\n",
    "        # Padding oder Truncating\n",
    "        if len(vec) < max_len:\n",
    "            vec += [0] * (max_len - len(vec))\n",
    "        else:\n",
    "            vec = vec[:max_len]\n",
    "        encoded_batch.append(vec)\n",
    "    return np.array(encoded_batch)\n",
    "\n",
    "print(\"Vektorisiere Daten (das dauert kurz)...\")\n",
    "X_train_enc = torch.tensor(encode_urls(X_train), dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_enc = torch.tensor(encode_urls(X_test), dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# DataLoader erstellen (für Batching)\n",
    "train_loader = DataLoader(TensorDataset(X_train_enc, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_enc, y_test_tensor), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c75fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DAS CNN MODELL (PyTorch Version) ---\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=32):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Conv Layer 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Conv Layer 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1) # Global Max Pooling\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len] -> [batch, seq_len, embed]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Conv1D erwartet [batch, channels, seq_len], wir müssen die Dimensionen tauschen\n",
    "        x = x.permute(0, 2, 1) \n",
    "        \n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "        x = self.global_pool(self.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten für Dense Layer: [batch, 64, 1] -> [batch, 64]\n",
    "        x = x.squeeze(-1) \n",
    "        \n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Modell initialisieren und auf GPU schieben\n",
    "model = CNNModel(vocab_size=vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "monitor = PerformanceMonitor(\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33dc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Training...\n",
      "Epoch 1 fertig.\n",
      "Epoch 2 fertig.\n",
      "Epoch 3 fertig.\n",
      "--- Ergebnisse CNN (Training) ---\n",
      "Zeit: 32.8799s | GPU-Last: 50.1%\n",
      "VRAM (System): 1450.92 MB | VRAM (Torch): 44.56 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'CNN',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 32.8799,\n",
       " 'ram_mb': 1666.48,\n",
       " 'vram_mb': 1450.92,\n",
       " 'torch_vram_mb': 44.56,\n",
       " 'cpu_percent': 113.3,\n",
       " 'gpu_util_percent': 50.1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4. TRAINING ---\n",
    "print(\"Starte Training...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} fertig.\")\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b5fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference (entire test set)...\n",
      "--- Ergebnisse CNN (Inferenz) ---\n",
      "Zeit: 1.6696s | GPU-Last: 49.8%\n",
      "VRAM (System): 1341.04 MB | VRAM (Torch): 34.02 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'CNN',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 1.6696,\n",
       " 'ram_mb': 1687.63,\n",
       " 'vram_mb': 1341.04,\n",
       " 'torch_vram_mb': 34.02,\n",
       " 'cpu_percent': 85.0,\n",
       " 'gpu_util_percent': 49.8,\n",
       " 'accuracy': 0.9926,\n",
       " 'precision': 0.9965,\n",
       " 'recall': 0.9899,\n",
       " 'f1_score': 0.9932,\n",
       " 'auc': 0.9996,\n",
       " 'fpr': np.float64(0.0042)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 5. INFERENCE & EVALUATION ---\n",
    "print(\"Starting inference (entire test set)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for efficiency during inference\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        \n",
    "        # Model prediction\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # Move data to CPU for metric calculation with sklearn\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Stop measurement here to capture pure model inference + data transfer time\n",
    "# Metrics calculation is excluded from the performance benchmark time\n",
    "\n",
    "# --- CALCULATE METRICS ---\n",
    "# Convert lists to numpy arrays\n",
    "y_true = np.array(all_labels)\n",
    "y_scores = np.array(all_preds) # Probabilities (Sigmoid output)\n",
    "y_pred_binary = (y_scores > 0.5).astype(int) # Hard predictions (0 or 1)\n",
    "\n",
    "# 1. Accuracy: Overall correctness\n",
    "acc = accuracy_score(y_true, y_pred_binary)\n",
    "# 2. Precision: Ability not to label a negative sample as positive\n",
    "prec = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 3. Recall: Ability to find all positive samples\n",
    "rec = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 4. F1 Score: Harmonic mean of precision and recall\n",
    "f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 5. AUC: Area Under the ROC Curve (performance across thresholds)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# 6. False Positive Rate (FPR)\n",
    "# Confusion Matrix components: true negative, false positive, false negative, true positive\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# Aggregate results\n",
    "metrics = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "# Pass metrics to the monitor for final logging\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
