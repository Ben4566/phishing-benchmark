{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e0b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laufe auf: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from benchmark import PerformanceMonitor  # Ihr Benchmark-Skript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 1. KONFIGURATION & DATEN ---\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Laufe auf: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfaa328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imbalanced_test_split(X, y, test_phish_count=50, ratio=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Creates a custom train/test split with a fixed ratio of 1000:1 (Legit:Phish) in the test set.\n",
    "    \n",
    "    Args:\n",
    "        X: Features (Dataframe, Series, or List)\n",
    "        y: Labels (Dataframe, Series, or List/Array)\n",
    "        test_phish_count: How many phishing URLs to put in the Test Set.\n",
    "        ratio: How many legitimate URLs per phishing URL (default 1000).\n",
    "        seed: Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Ensure inputs are standard format (Pandas Series or Numpy Array) for indexing\n",
    "    if isinstance(X, list): X = np.array(X)\n",
    "    if isinstance(y, list): y = np.array(y)\n",
    "    \n",
    "    # If X/y are DataFrames, extract the underlying array/series\n",
    "    if isinstance(y, pd.DataFrame): y = y.iloc[:, 0]\n",
    "    \n",
    "    # Identify indices\n",
    "    # We assume Label 1 = Phishing, Label 0 = Legitimate\n",
    "    phish_indices = np.where(y == 1)[0]\n",
    "    legit_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Calculate Test Sizes\n",
    "    n_test_phish = test_phish_count\n",
    "    n_test_legit = test_phish_count * ratio\n",
    "    \n",
    "    # Checks\n",
    "    if len(phish_indices) < n_test_phish:\n",
    "        raise ValueError(f\"Not enough Phishing samples. Have {len(phish_indices)}, need {n_test_phish}\")\n",
    "    if len(legit_indices) < n_test_legit:\n",
    "        raise ValueError(f\"Not enough Legitimate samples. Have {len(legit_indices)}, need {n_test_legit}\")\n",
    "        \n",
    "    print(f\"Creating 1000:1 Test Split...\")\n",
    "    print(f\"Test Set: {n_test_phish} Phishing, {n_test_legit} Legitimate (Total: {n_test_phish + n_test_legit})\")\n",
    "    \n",
    "    # Shuffle indices\n",
    "    np.random.shuffle(phish_indices)\n",
    "    np.random.shuffle(legit_indices)\n",
    "    \n",
    "    # Select Indices for Test\n",
    "    test_idx_phish = phish_indices[:n_test_phish]\n",
    "    test_idx_legit = legit_indices[:n_test_legit]\n",
    "    test_indices = np.concatenate([test_idx_phish, test_idx_legit])\n",
    "    np.random.shuffle(test_indices) # Shuffle the test set itself\n",
    "    \n",
    "    # Select Indices for Train (The Rest)\n",
    "    train_idx_phish = phish_indices[n_test_phish:]\n",
    "    train_idx_legit = legit_indices[n_test_legit:]\n",
    "    train_indices = np.concatenate([train_idx_phish, train_idx_legit])\n",
    "    np.random.shuffle(train_indices) # Shuffle the train set\n",
    "    \n",
    "    # Perform Split\n",
    "    # Handle pandas vs numpy indexing\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    else:\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2de95b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading legitimate URLs...\n",
      "Loading phishing URLs...\n",
      "Creating 1000:1 Test Split...\n",
      "Test Set: 50 Phishing, 50000 Legitimate (Total: 50050)\n",
      "Training on 231317 URLs, Testing on 50050 URLs.\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"\n",
    "    Loads URLs and labels from text files into lists.\n",
    "    Returns: (list of strings, list of integers)\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    labels = []\n",
    "\n",
    "    # 1. Load Legitimate URLs (Label = 0)\n",
    "    print(\"Loading legitimate URLs...\")\n",
    "    try:\n",
    "        with open(r\"..\\data\\raw\\url_legitimate_safebrowsing.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                url = parts[0].strip()\n",
    "                if url:\n",
    "                    urls.append(url)\n",
    "                    labels.append(0)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: Legitimate file not found.\")\n",
    "\n",
    "    # 2. Load Phishing URLs (Label = 1)\n",
    "    print(\"Loading phishing URLs...\")\n",
    "    try:\n",
    "        with open(r\"..\\data\\raw\\url_raw_phishing.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                url = parts[0].strip()\n",
    "                if url:\n",
    "                    urls.append(url)\n",
    "                    labels.append(1)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: Phishing file not found.\")\n",
    "\n",
    "    return urls, np.array(labels)\n",
    "\n",
    "# --- 1. PREPARE DATA ---\n",
    "raw_urls, labels = load_raw_data()\n",
    "\n",
    "# Split into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = get_imbalanced_test_split(raw_urls, labels, test_phish_count=50, ratio=1000)\n",
    "\n",
    "print(f\"Training on {len(X_train)} URLs, Testing on {len(X_test)} URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d769603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektorisiere Daten (das dauert kurz)...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. VECTORIZATION (Manuell für PyTorch) ---\n",
    "# Wir bauen ein einfaches Vokabular (Zeichen-basiert), genau wie Keras TextVectorization\n",
    "chars = sorted(list(set(\"\".join(X_train[:1000])))) # Schnelles Vocab aus den ersten 1000 URLs\n",
    "char_to_int = {c: i+2 for i, c in enumerate(chars)} # +2 für Padding (0) und UNK (1)\n",
    "vocab_size = len(char_to_int) + 2\n",
    "\n",
    "def encode_urls(urls, max_len=MAX_LEN):\n",
    "    encoded_batch = []\n",
    "    for url in urls:\n",
    "        # Zeichen zu Int konvertieren\n",
    "        vec = [char_to_int.get(c, 1) for c in url] # 1 = Unknown\n",
    "        # Padding oder Truncating\n",
    "        if len(vec) < max_len:\n",
    "            vec += [0] * (max_len - len(vec))\n",
    "        else:\n",
    "            vec = vec[:max_len]\n",
    "        encoded_batch.append(vec)\n",
    "    return np.array(encoded_batch)\n",
    "\n",
    "print(\"Vektorisiere Daten (das dauert kurz)...\")\n",
    "X_train_enc = torch.tensor(encode_urls(X_train), dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_enc = torch.tensor(encode_urls(X_test), dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# DataLoader erstellen (für Batching)\n",
    "train_loader = DataLoader(TensorDataset(X_train_enc, y_train_tensor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_enc, y_test_tensor), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c75fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DAS CNN MODELL (PyTorch Version) ---\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=32):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Conv Layer 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Conv Layer 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1) # Global Max Pooling\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len] -> [batch, seq_len, embed]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Conv1D erwartet [batch, channels, seq_len], wir müssen die Dimensionen tauschen\n",
    "        x = x.permute(0, 2, 1) \n",
    "        \n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "        x = self.global_pool(self.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten für Dense Layer: [batch, 64, 1] -> [batch, 64]\n",
    "        x = x.squeeze(-1) \n",
    "        \n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Modell initialisieren und auf GPU schieben\n",
    "model = CNNModel(vocab_size=vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "monitor = PerformanceMonitor(\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33dc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Training...\n",
      "Epoch 1 fertig.\n",
      "Epoch 2 fertig.\n",
      "Epoch 3 fertig.\n",
      "--- Ergebnisse CNN (Training) ---\n",
      "Zeit: 36.3923s | GPU-Last: 42.4%\n",
      "VRAM (System): 1530.38 MB | VRAM (Torch): 44.56 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'CNN',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 36.3923,\n",
       " 'ram_mb': 26174.36,\n",
       " 'vram_mb': 1530.38,\n",
       " 'torch_vram_mb': 44.56,\n",
       " 'cpu_percent': 107.5,\n",
       " 'gpu_util_percent': 42.4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4. TRAINING ---\n",
    "print(\"Starte Training...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} fertig.\")\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b5fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference (entire test set)...\n",
      "--- Ergebnisse CNN (Inferenz) ---\n",
      "Zeit: 1.7246s | GPU-Last: 25.8%\n",
      "VRAM (System): 1529.13 MB | VRAM (Torch): 34.02 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'CNN',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 1.7246,\n",
       " 'ram_mb': 25828.5,\n",
       " 'vram_mb': 1529.13,\n",
       " 'torch_vram_mb': 34.02,\n",
       " 'cpu_percent': 73.0,\n",
       " 'gpu_util_percent': 25.8,\n",
       " 'accuracy': 0.9886,\n",
       " 'precision': 0.0794,\n",
       " 'recall': 0.98,\n",
       " 'f1_score': 0.1469,\n",
       " 'auc': 0.9996,\n",
       " 'fpr': np.float64(0.0114)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 5. INFERENCE & EVALUATION ---\n",
    "print(\"Starting inference (entire test set)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for efficiency during inference\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        \n",
    "        # Model prediction\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # Move data to CPU for metric calculation with sklearn\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Stop measurement here to capture pure model inference + data transfer time\n",
    "# Metrics calculation is excluded from the performance benchmark time\n",
    "\n",
    "# --- CALCULATE METRICS ---\n",
    "# Convert lists to numpy arrays\n",
    "y_true = np.array(all_labels)\n",
    "y_scores = np.array(all_preds) # Probabilities (Sigmoid output)\n",
    "y_pred_binary = (y_scores > 0.5).astype(int) # Hard predictions (0 or 1)\n",
    "\n",
    "# 1. Accuracy: Overall correctness\n",
    "acc = accuracy_score(y_true, y_pred_binary)\n",
    "# 2. Precision: Ability not to label a negative sample as positive\n",
    "prec = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 3. Recall: Ability to find all positive samples\n",
    "rec = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 4. F1 Score: Harmonic mean of precision and recall\n",
    "f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 5. AUC: Area Under the ROC Curve (performance across thresholds)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# 6. False Positive Rate (FPR)\n",
    "# Confusion Matrix components: true negative, false positive, false negative, true positive\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# Aggregate results\n",
    "metrics = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "# Pass metrics to the monitor for final logging\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
