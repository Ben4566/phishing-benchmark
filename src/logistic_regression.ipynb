{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd8fd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from benchmark import PerformanceMonitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_loader import load_and_standardize_data\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9ef770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Loader] Starte Laden von: feature_all.txt ---\n",
      "--- [Loader] Fertig. Features: 201, Samples: 507171 ---\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r\"..\\data\\processed\\feature_all.txt\" \n",
    "TARGET_COL = \"Phishing?\"\n",
    "DELIMITER = \" \"\n",
    "\n",
    "X, y = load_and_standardize_data(FILE_PATH, TARGET_COL, DELIMITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57253d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train_x, url_temp_x, url_train_y, url_temp_y = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "url_val_x, url_test_x, url_val_y, url_test_y = train_test_split(url_temp_x, url_temp_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80be6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "url_train_x = scaler.fit_transform(url_train_x)\n",
    "url_val_x = scaler.transform(url_val_x) # Nur transform, nicht fitten!\n",
    "url_test_x = scaler.transform(url_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f535f102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training läuft auf: cuda\n",
      "Starte Training für 500 Epochen...\n",
      "--- Ergebnisse Logistic Regression (Training) ---\n",
      "Zeit: 13.0112s | GPU-Last: 86.5%\n",
      "VRAM (System): 1649.14 MB | VRAM (Torch): 309.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic Regression',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 13.0112,\n",
       " 'ram_mb': 3646.82,\n",
       " 'vram_mb': 1649.14,\n",
       " 'torch_vram_mb': 309.4,\n",
       " 'cpu_percent': 95.9,\n",
       " 'gpu_util_percent': 86.5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Monitor starten\n",
    "monitor = PerformanceMonitor(\"Logistic Regression\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# 1. GPU Setup prüfen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training läuft auf: {device}\")\n",
    "\n",
    "# 2. PyTorch Model Definition (Wrapper, der sich wie sklearn verhält)\n",
    "class GPULogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GPULogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "    # Hilfsfunktion, um sklearn-API nachzubauen\n",
    "    def fit(self, X, y, epochs=100, lr=0.01, batch_size=4096):\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        \n",
    "        # Daten zu Tensoren konvertieren\n",
    "        # .values nutzen, falls es Pandas Dataframes sind\n",
    "        X_np = X.values if hasattr(X, 'values') else X\n",
    "        y_np = y.values if hasattr(y, 'values') else y\n",
    "        \n",
    "        X_tensor = torch.tensor(X_np, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "        # Training Loop (Mini-Batch)\n",
    "        num_samples = X_tensor.shape[0]\n",
    "        num_batches = int(np.ceil(num_samples / batch_size))\n",
    "        \n",
    "        print(f\"Starte Training für {epochs} Epochen...\")\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle indices\n",
    "            indices = torch.randperm(num_samples, device=device)\n",
    "            \n",
    "            for i in range(num_batches):\n",
    "                start = i * batch_size\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(X_tensor[batch_idx])\n",
    "                loss = criterion(outputs, y_tensor[batch_idx])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            probs = self.predict_proba(X)[:, 1]\n",
    "            return (probs >= 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        X_np = X.values if hasattr(X, 'values') else X\n",
    "        X_tensor = torch.tensor(X_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(X_tensor)\n",
    "            probs = outputs.cpu().numpy().flatten()\n",
    "            \n",
    "        # Formatieren wie sklearn: [[prob_0, prob_1], ...]\n",
    "        return np.vstack(((1 - probs), probs)).T\n",
    "\n",
    "# 3. Modell initialisieren und trainieren\n",
    "input_dim = url_train_x.shape[1]\n",
    "log_reg = GPULogisticRegression(input_dim)\n",
    "\n",
    "# Hyperparameter anpassen falls nötig (batch_size erhöht für GPU-Effizienz)\n",
    "log_reg.fit(url_train_x, url_train_y, epochs=500, lr=0.001, batch_size=16384)\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9260a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz (gesamtes Testset)...\n",
      "--- Ergebnisse Logistic Regression (Inferenz) ---\n",
      "Zeit: 0.1011s | GPU-Last: 0.0%\n",
      "VRAM (System): 1311.21 MB | VRAM (Torch): 75.17 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic Regression',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 0.1011,\n",
       " 'ram_mb': 3390.47,\n",
       " 'vram_mb': 1311.21,\n",
       " 'torch_vram_mb': 75.17,\n",
       " 'cpu_percent': 774.1,\n",
       " 'gpu_util_percent': 0.0,\n",
       " 'accuracy': 0.962,\n",
       " 'precision': 0.9151,\n",
       " 'recall': 0.8399,\n",
       " 'f1_score': 0.8759,\n",
       " 'auc': 0.9792,\n",
       " 'fpr': np.float64(0.0148)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 5. INFERENZ & EVALUIERUNG ---\n",
    "print(\"Starte Inferenz (gesamtes Testset)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# 1. Vorhersage (Inferenz)\n",
    "# Deine Klasse kümmert sich intern um .to(device) und .cpu()\n",
    "# predict_proba gibt [[prob_0, prob_1], ...] zurück, wir brauchen Spalte 1\n",
    "y_scores = log_reg.predict_proba(url_test_x)[:, 1]\n",
    "\n",
    "# 2. Ground Truth (Echte Labels)\n",
    "# Sicherstellen, dass es ein Numpy Array ist\n",
    "y_true = url_test_y.values if hasattr(url_test_y, 'values') else url_test_y\n",
    "\n",
    "# 3. Binäre Vorhersagen (Threshold 0.5)\n",
    "y_pred_binary = (y_scores > 0.5).astype(int)\n",
    "\n",
    "# --- METRIKEN BERECHNEN ---\n",
    "# 1. Accuracy\n",
    "acc = accuracy_score(y_true, y_pred_binary)\n",
    "# 2. Precision\n",
    "prec = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 3. Recall\n",
    "rec = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 4. F1 Score\n",
    "f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 5. AUC\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# 6. False Positive Rate (FPR)\n",
    "# Confusion Matrix: tn, fp, fn, tp\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# Ergebnisse zusammenpacken\n",
    "metrics_dict = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "# An Monitor übergeben\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
