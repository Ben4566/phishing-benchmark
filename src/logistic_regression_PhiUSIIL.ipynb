{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd8fd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression mit PhiUSIIL Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from benchmark import PerformanceMonitor\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6caaf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade lokalen Datensatz: ..\\data\\processed\\PhiUSIIL_Phishing_URL_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# --- NEUER TEIL: LOKALE DATEN LADEN ---\n",
    "\n",
    "# 1. PFAD ANPASSEN: Hier den Pfad zu deiner CSV-Datei eintragen\n",
    "# Das 'r' davor ist wichtig für Windows-Pfade!\n",
    "dateipfad = r\"..\\data\\processed\\PhiUSIIL_Phishing_URL_Dataset.csv\" \n",
    "\n",
    "print(f\"Lade lokalen Datensatz: {dateipfad}\")\n",
    "\n",
    "# Einlesen der CSV\n",
    "dataset = pd.read_csv(dateipfad)\n",
    "\n",
    "# 1. 'URL'-Textspalte entfernen (falls vorhanden), da Modelle Zahlen brauchen\n",
    "if 'URL' in dataset.columns:\n",
    "    dataset = dataset.drop(columns=['URL'])\n",
    "\n",
    "# 2. Target-Spalte umbenennen zu 'Phishing?'\n",
    "# Hinweis: In der CSV heißt die Zielspalte oft 'label', 'URLLabel' oder 'class'.\n",
    "# Wir suchen sie und benennen sie um, damit dein restlicher Code funktioniert.\n",
    "\n",
    "# Versuche typische Namen zu finden:\n",
    "target_candidates = ['label', 'URLLabel', 'class', 'Phishing']\n",
    "target_found = False\n",
    "\n",
    "for candidate in target_candidates:\n",
    "    if candidate in dataset.columns:\n",
    "        dataset.rename(columns={candidate: 'Phishing?'}, inplace=True)\n",
    "        target_found = True\n",
    "        break\n",
    "\n",
    "# Fallback: Wenn wir den Namen nicht erraten, nehmen wir einfach die allerletzte Spalte\n",
    "if not target_found:\n",
    "    print(\"Warnung: Konnte Target-Name nicht automatisch finden. Nutze die letzte Spalte als Target.\")\n",
    "    last_col = dataset.columns[-1]\n",
    "    dataset.rename(columns={last_col: 'Phishing?'}, inplace=True)\n",
    "\n",
    "# 3. Sicherstellen, dass alles numerisch ist (Textspalten entfernen)\n",
    "dataset = dataset.select_dtypes(include=[np.number])\n",
    "\n",
    "# 4. X und y definieren (damit der Rest deines Codes weiterläuft)\n",
    "# y ist jetzt die Spalte 'Phishing?'\n",
    "y = dataset['Phishing?']\n",
    "X = dataset.drop(columns=['Phishing?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57253d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train, url_dummy = train_test_split(dataset, test_size=0.2)\n",
    "url_val, url_test = train_test_split(url_dummy, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be6cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train_x = url_train.drop(columns=\"Phishing?\", inplace=False)\n",
    "url_train_y = url_train[\"Phishing?\"]\n",
    "\n",
    "url_val_x = url_val.drop(columns=\"Phishing?\", inplace=False)\n",
    "url_val_y = url_val[\"Phishing?\"]\n",
    "\n",
    "url_test_x = url_test.drop(columns=\"Phishing?\", inplace=False)\n",
    "url_test_y = url_test[\"Phishing?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322cfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training läuft auf: cuda\n",
      "Starte Training für 500 Epochen...\n",
      "--- Ergebnisse Logistic Regression PhiUSIIL (Training) ---\n",
      "Zeit: 6.8372s | GPU-Last: 30.7%\n",
      "VRAM (System): 2109.67 MB | VRAM (Torch): 63.42 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic Regression PhiUSIIL',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 6.8372,\n",
       " 'ram_mb': 1362.38,\n",
       " 'vram_mb': 2109.67,\n",
       " 'torch_vram_mb': 63.42,\n",
       " 'cpu_percent': 120.4,\n",
       " 'gpu_util_percent': 30.7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monitor starten\n",
    "monitor = PerformanceMonitor(\"Logistic Regression PhiUSIIL\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# 1. GPU Setup prüfen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training läuft auf: {device}\")\n",
    "\n",
    "# 2. PyTorch Model Definition (Wrapper, der sich wie sklearn verhält)\n",
    "class GPULogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GPULogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "    # Hilfsfunktion, um sklearn-API nachzubauen\n",
    "    def fit(self, X, y, epochs=100, lr=0.01, batch_size=4096):\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        \n",
    "        # Daten zu Tensoren konvertieren\n",
    "        # .values nutzen, falls es Pandas Dataframes sind\n",
    "        X_np = X.values if hasattr(X, 'values') else X\n",
    "        y_np = y.values if hasattr(y, 'values') else y\n",
    "        \n",
    "        X_tensor = torch.tensor(X_np, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "        # Training Loop (Mini-Batch)\n",
    "        num_samples = X_tensor.shape[0]\n",
    "        num_batches = int(np.ceil(num_samples / batch_size))\n",
    "        \n",
    "        print(f\"Starte Training für {epochs} Epochen...\")\n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle indices\n",
    "            indices = torch.randperm(num_samples, device=device)\n",
    "            \n",
    "            for i in range(num_batches):\n",
    "                start = i * batch_size\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(X_tensor[batch_idx])\n",
    "                loss = criterion(outputs, y_tensor[batch_idx])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            probs = self.predict_proba(X)[:, 1]\n",
    "            return (probs >= 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        X_np = X.values if hasattr(X, 'values') else X\n",
    "        X_tensor = torch.tensor(X_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(X_tensor)\n",
    "            probs = outputs.cpu().numpy().flatten()\n",
    "            \n",
    "        # Formatieren wie sklearn: [[prob_0, prob_1], ...]\n",
    "        return np.vstack(((1 - probs), probs)).T\n",
    "\n",
    "# 3. Modell initialisieren und trainieren\n",
    "input_dim = url_train_x.shape[1]\n",
    "log_reg = GPULogisticRegression(input_dim)\n",
    "\n",
    "# Hyperparameter anpassen falls nötig (batch_size erhöht für GPU-Effizienz)\n",
    "log_reg.fit(url_train_x, url_train_y, epochs=500, lr=0.001, batch_size=16384)\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8e2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz (gesamtes Testset)...\n",
      "--- Ergebnisse Logistic Regression PhiUSIIL (Inferenz) ---\n",
      "Zeit: 0.1011s | GPU-Last: 31.0%\n",
      "VRAM (System): 1639.8 MB | VRAM (Torch): 21.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic Regression PhiUSIIL',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 0.1011,\n",
       " 'ram_mb': 1578.99,\n",
       " 'vram_mb': 1639.8,\n",
       " 'torch_vram_mb': 21.0,\n",
       " 'cpu_percent': 724.4,\n",
       " 'gpu_util_percent': 31.0,\n",
       " 'accuracy': 0.9992,\n",
       " 'precision': 0.999,\n",
       " 'recall': 0.9995,\n",
       " 'f1_score': 0.9993,\n",
       " 'auc': 0.9999,\n",
       " 'fpr': np.float64(0.0013)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- 5. INFERENZ & EVALUIERUNG ---\n",
    "print(\"Starte Inferenz (gesamtes Testset)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# 1. Vorhersage (Inferenz)\n",
    "# Deine Klasse kümmert sich intern um .to(device) und .cpu()\n",
    "# predict_proba gibt [[prob_0, prob_1], ...] zurück, wir brauchen Spalte 1\n",
    "y_scores = log_reg.predict_proba(url_test_x)[:, 1]\n",
    "\n",
    "# 2. Ground Truth (Echte Labels)\n",
    "# Sicherstellen, dass es ein Numpy Array ist\n",
    "y_true = url_test_y.values if hasattr(url_test_y, 'values') else url_test_y\n",
    "\n",
    "# 3. Binäre Vorhersagen (Threshold 0.5)\n",
    "y_pred_binary = (y_scores > 0.5).astype(int)\n",
    "\n",
    "# --- METRIKEN BERECHNEN ---\n",
    "# 1. Accuracy\n",
    "acc = accuracy_score(y_true, y_pred_binary)\n",
    "# 2. Precision\n",
    "prec = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 3. Recall\n",
    "rec = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 4. F1 Score\n",
    "f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "# 5. AUC\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# 6. False Positive Rate (FPR)\n",
    "# Confusion Matrix: tn, fp, fn, tp\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# Ergebnisse zusammenpacken\n",
    "metrics_dict = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "# An Monitor übergeben\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
