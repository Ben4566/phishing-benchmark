{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72597ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "from benchmark import PerformanceMonitor\n",
    "from xgboost import XGBClassifier\n",
    "from data_loader import load_and_standardize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11404b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Loader] Starte Laden von: feature_all.txt ---\n",
      "--- [Loader] Fertig. Features: 201, Samples: 507171 ---\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r\"..\\data\\processed\\feature_all.txt\"\n",
    "# Hinweis: feature_all.txt ist oft leerzeichen-getrennt\n",
    "X, y = load_and_standardize_data(FILE_PATH, target_col_name=\"Phishing?\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea30efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Führe Split durch...\n"
     ]
    }
   ],
   "source": [
    "# Split (Standardisiert)\n",
    "print(\"Führe Split durch...\")\n",
    "url_train_x, url_temp_x, url_train_y, url_temp_y = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "url_val_x, url_test_x, url_val_y, url_test_y = train_test_split(url_temp_x, url_temp_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a502045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. FORMATIERUNG ---\n",
    "X_train = url_train_x.astype('float32')\n",
    "y_train = url_train_y.astype('float32')\n",
    "\n",
    "X_val = url_val_x.astype('float32')\n",
    "y_val = url_val_y.astype('float32')\n",
    "\n",
    "X_test = url_test_x.astype('float32')\n",
    "y_test = url_test_y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b4680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Training...\n",
      "--- Ergebnisse XGBoost (Training) ---\n",
      "Zeit: 52.7698s | GPU-Last: 76.8%\n",
      "VRAM (System): 2173.56 MB | VRAM (Torch): 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'XGBoost',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 52.7698,\n",
       " 'ram_mb': 3590.32,\n",
       " 'vram_mb': 2173.56,\n",
       " 'torch_vram_mb': 0.0,\n",
       " 'cpu_percent': 112.7,\n",
       " 'gpu_util_percent': 76.8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Monitor initialisieren\n",
    "monitor = PerformanceMonitor(\"XGBoost\")\n",
    "\n",
    "# --- TRAINING ---\n",
    "print(\"Starte Training...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# --- VORBEREITUNG ---\n",
    "# Daten vorher umwandeln, um Kopieren während des Trainings zu vermeiden\n",
    "X_train = url_train_x.astype('float32')\n",
    "y_train = url_train_y.astype('float32')\n",
    "X_val = url_val_x.astype('float32')\n",
    "y_val = url_val_y.astype('float32')\n",
    "\n",
    "\n",
    "bst = XGBClassifier(\n",
    "    n_estimators=5000,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    objective='binary:logistic',\n",
    "    early_stopping_rounds=50,\n",
    "    tree_method=\"hist\",  # Effizientester Algorithmus für GPU\n",
    "    device=\"cuda\"        # Aktiviert die GPU\n",
    ")\n",
    "\n",
    "# Training durchführen\n",
    "# Wir nutzen .astype(float), um Warnungen bei booleschen/object Spalten zu vermeiden\n",
    "bst.fit(\n",
    "    url_train_x.astype(float), \n",
    "    url_train_y.astype(float),\n",
    "    eval_set=[(url_val_x.astype(float), url_val_y.astype(float))], \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3d11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz (gesamtes Testset)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [18:53:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ergebnisse XGBoost (Inferenz) ---\n",
      "Zeit: 2.0028s | GPU-Last: 80.0%\n",
      "VRAM (System): 2145.56 MB | VRAM (Torch): 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'XGBoost',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 2.0028,\n",
       " 'ram_mb': 3713.11,\n",
       " 'vram_mb': 2145.56,\n",
       " 'torch_vram_mb': 0.0,\n",
       " 'cpu_percent': 316.4,\n",
       " 'gpu_util_percent': 80.0,\n",
       " 'accuracy': 0.9908,\n",
       " 'precision': 0.9874,\n",
       " 'recall': 0.9547,\n",
       " 'f1_score': 0.9708,\n",
       " 'auc': 0.9979,\n",
       " 'fpr': np.float64(0.0023)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- INFERENZ ---\n",
    "print(\"Starte Inferenz (gesamtes Testset)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "X_test_ready = url_test_x.astype(float)\n",
    "y_scores = bst.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred = bst.predict(X_test_ready)\n",
    "\n",
    "# --- METRIKEN BERECHNEN ---\n",
    "y_true = url_test_y.astype(float).values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# KORREKTUR: Dictionary umbenannt, damit 'metrics' Modul nicht überschrieben wird\n",
    "metrics_dict = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
