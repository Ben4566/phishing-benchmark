{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72597ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "from benchmark import PerformanceMonitor\n",
    "from xgboost import XGBClassifier\n",
    "from data_loader import load_and_standardize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0dfe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Loader] Starte Laden von: PhiUSIIL_Phishing_URL_Dataset.csv ---\n",
      "--- [Loader] Fertig. Features: 50, Samples: 235795 ---\n"
     ]
    }
   ],
   "source": [
    "# Konfiguration\n",
    "FILE_PATH = r\"..\\data\\processed\\PhiUSIIL_Phishing_URL_Dataset.csv\"\n",
    "# Hier ist es Komma-getrennt und heißt 'label'\n",
    "X, y = load_and_standardize_data(FILE_PATH, target_col_name=\"label\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b0523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Führe Split durch...\n"
     ]
    }
   ],
   "source": [
    "# Split (Identisch zum anderen Notebook!)\n",
    "print(\"Führe Split durch...\")\n",
    "url_train_x, url_temp_x, url_train_y, url_temp_y = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "url_val_x, url_test_x, url_val_y, url_test_y = train_test_split(url_temp_x, url_temp_y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfbf8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Führe Train/Test Split durch (Random Seed 42)...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. SPLITTING (Der wichtigste Teil für Fairness) ---\n",
    "# random_state=42 sorgt dafür, dass beide Datensätze \"gleich zufällig\" gemischt werden\n",
    "print(\"Führe Train/Test Split durch (Random Seed 42)...\")\n",
    "\n",
    "url_train_x, url_temp_x, url_train_y, url_temp_y = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "url_val_x, url_test_x, url_val_y, url_test_y = train_test_split(\n",
    "    url_temp_x, url_temp_y, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d89d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datenvorbereitung abgeschlossen. Startklar für Benchmark.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. FORMATIERUNG ---\n",
    "# Sicherstellen, dass alles float32 ist (für GPU Speed)\n",
    "X_train = url_train_x.astype('float32')\n",
    "y_train = url_train_y.astype('float32')\n",
    "X_val = url_val_x.astype('float32')\n",
    "y_val = url_val_y.astype('float32')\n",
    "# Testdaten (falls für Inferenz gebraucht)\n",
    "X_test = url_test_x.astype('float32')\n",
    "y_test = url_test_y.astype('float32')\n",
    "\n",
    "print(\"Datenvorbereitung abgeschlossen. Startklar für Benchmark.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b4680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Training...\n",
      "--- Ergebnisse XGBoost PhiUSIIL (Training) ---\n",
      "Zeit: 6.608s | GPU-Last: 50.7%\n",
      "VRAM (System): 1379.82 MB | VRAM (Torch): 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'XGBoost PhiUSIIL',\n",
       " 'task': 'Training',\n",
       " 'time_sec': 6.608,\n",
       " 'ram_mb': 1084.25,\n",
       " 'vram_mb': 1379.82,\n",
       " 'torch_vram_mb': 0.0,\n",
       " 'cpu_percent': 167.6,\n",
       " 'gpu_util_percent': 50.7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Monitor initialisieren\n",
    "monitor = PerformanceMonitor(\"XGBoost PhiUSIIL\")\n",
    "\n",
    "# --- TRAINING ---\n",
    "print(\"Starte Training...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "# --- VORBEREITUNG ---\n",
    "# Daten vorher umwandeln, um Kopieren während des Trainings zu vermeiden\n",
    "X_train = url_train_x.astype('float32')\n",
    "y_train = url_train_y.astype('float32')\n",
    "X_val = url_val_x.astype('float32')\n",
    "y_val = url_val_y.astype('float32')\n",
    "\n",
    "\n",
    "bst = XGBClassifier(\n",
    "    n_estimators=5000,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    objective='binary:logistic',\n",
    "    early_stopping_rounds=50,\n",
    "    tree_method=\"hist\",  # Effizientester Algorithmus für GPU\n",
    "    device=\"cuda\"        # Aktiviert die GPU\n",
    ")\n",
    "\n",
    "# Training durchführen\n",
    "# Wir nutzen .astype(float), um Warnungen bei booleschen/object Spalten zu vermeiden\n",
    "bst.fit(\n",
    "    url_train_x.astype(float), \n",
    "    url_train_y.astype(float),\n",
    "    eval_set=[(url_val_x.astype(float), url_val_y.astype(float))], \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "monitor.end_measurement(task_name=\"Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3d11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inferenz (gesamtes Testset)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GitHub Repositorys\\Evaluation_of_AI_Models\\.venv\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [18:56:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ergebnisse XGBoost PhiUSIIL (Inferenz) ---\n",
      "Zeit: 0.3013s | GPU-Last: 10.7%\n",
      "VRAM (System): 1303.95 MB | VRAM (Torch): 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'XGBoost PhiUSIIL',\n",
       " 'task': 'Inferenz',\n",
       " 'time_sec': 0.3013,\n",
       " 'ram_mb': 1096.17,\n",
       " 'vram_mb': 1303.95,\n",
       " 'torch_vram_mb': 0.0,\n",
       " 'cpu_percent': 1068.3,\n",
       " 'gpu_util_percent': 10.7,\n",
       " 'accuracy': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1_score': 1.0,\n",
       " 'auc': 1.0,\n",
       " 'fpr': np.float64(0.0)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- INFERENZ ---\n",
    "print(\"Starte Inferenz (gesamtes Testset)...\")\n",
    "monitor.start_measurement()\n",
    "\n",
    "X_test_ready = url_test_x.astype(float)\n",
    "y_scores = bst.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred = bst.predict(X_test_ready)\n",
    "\n",
    "# --- METRIKEN BERECHNEN ---\n",
    "y_true = url_test_y.astype(float).values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# KORREKTUR: Dictionary umbenannt, damit 'metrics' Modul nicht überschrieben wird\n",
    "metrics_dict = {\n",
    "    \"accuracy\": round(acc, 4),\n",
    "    \"precision\": round(prec, 4),\n",
    "    \"recall\": round(rec, 4),\n",
    "    \"f1_score\": round(f1, 4),\n",
    "    \"auc\": round(auc, 4),\n",
    "    \"fpr\": round(fpr, 4)\n",
    "}\n",
    "\n",
    "monitor.end_measurement(task_name=\"Inferenz\", extra_metrics=metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
